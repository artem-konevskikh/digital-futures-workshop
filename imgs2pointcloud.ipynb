{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gan2pointcloud.ipynb","provenance":[{"file_id":"https://github.com/artem-konevskikh/ai-in-art/blob/main/03-stylegan2-ada.ipynb","timestamp":1605210014100}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LdWWSVywULkX"},"source":["# GAN to Point Cloud"]},{"cell_type":"code","metadata":{"id":"Wprx265RUGS7","cellView":"form"},"source":["#@title Install\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","\n","# Download the code\n","!git clone https://github.com/NVlabs/stylegan2-ada.git\n","%cd stylegan2-ada\n","\n","import glob\n","import argparse\n","import numpy as np\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import re\n","import sys\n","from io import BytesIO\n","import IPython.display\n","from math import ceil\n","import PIL\n","from PIL import Image, ImageDraw\n","import imageio\n","import os\n","import pickle\n","from google.colab import files\n","import struct\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2gfigaTsgZqe","cellView":"form","executionInfo":{"status":"ok","timestamp":1622547324544,"user_tz":-180,"elapsed":367,"user":{"displayName":"Артемий Двойное Дно","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG9pQ8FcJc9b3S76fMxNFSQB-LRvslG5G_q0XL=s64","userId":"12519032261696717131"}}},"source":["#@title Additional functions for image generation\n","# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_in_w_space(dlatents, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    Gs_kwargs.truncation_psi = truncation_psi\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","\n","    imgs = []\n","    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n","        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n","        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n","        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n","        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n","    return imgs       \n","\n","def generate_images(zs, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    if not isinstance(truncation_psi, list):\n","        truncation_psi = [truncation_psi] * len(zs)\n","        \n","    imgs = []\n","    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n","        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n","        noise_rnd = np.random.RandomState(1) # fix noise\n","        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n","        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n","        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n","    return imgs\n","\n","def generate_zs_from_seeds(seeds):\n","    zs = []\n","    for seed_idx, seed in enumerate(seeds):\n","        rnd = np.random.RandomState(seed)\n","        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n","        zs.append(z)\n","    return zs\n","\n","# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_from_seeds(seeds, truncation_psi):\n","    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n","\n","def saveImgs(imgs, location):\n","  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n","    file = location+ str(idx) + \".png\"\n","    img.save(file)\n","\n","def imshow(a, format='png', jpeg_fallback=True):\n","  a = np.asarray(a, dtype=np.uint8)\n","  str_file = BytesIO()\n","  PIL.Image.fromarray(a).save(str_file, format)\n","  im_data = str_file.getvalue()\n","  try:\n","    disp = IPython.display.display(IPython.display.Image(im_data))\n","  except IOError:\n","    if jpeg_fallback and format != 'jpeg':\n","      print ('Warning: image was too large to display in format \"{}\"; '\n","             'trying jpeg instead.').format(format)\n","      return imshow(a, format='jpeg')\n","    else:\n","      raise\n","  return disp\n","\n","def showarray(a, fmt='png'):\n","    a = np.uint8(a)\n","    f = StringIO()\n","    PIL.Image.fromarray(a).save(f, fmt)\n","    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n","\n","        \n","def clamp(x, minimum, maximum):\n","    return max(minimum, min(x, maximum))\n","    \n","def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n","  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n","   \n","  draw = ImageDraw.Draw(buffer)\n","  cy = (y+y2)/2\n","  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n","  for i in range(len(latents)):\n","    mx = x + (x2-x)*(float(i)/len(latents))\n","    h = (y2-y)*latents[i]*0.1\n","    h = clamp(h,cy-y2,y2-cy)\n","    draw.line((mx,cy,mx,cy+h),fill=color)\n","  return PIL.Image.alpha_composite(image,buffer)\n","             \n","  \n","def createImageGrid(images, scale=0.25, rows=1):\n","   w,h = images[0].size\n","   w = int(w*scale)\n","   h = int(h*scale)\n","   height = rows*h\n","   cols = ceil(len(images) / rows)\n","   width = cols*w\n","   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n","   for i,img in enumerate(images):\n","     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n","     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n","   return canvas\n","\n","def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n","  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n","  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","  for i in range(truncation_cutoff):\n","    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n","    \n","  return dlatent\n","\n","def interpolate(zs, steps):\n","   out = []\n","   for i in range(len(zs)-1):\n","    for index in range(steps):\n","     fraction = index/float(steps) \n","     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n","   return out\n","\n","# Taken from https://github.com/alexanderkuk/log-progress\n","def log_progress(sequence, every=1, size=None, name='Items'):\n","    from ipywidgets import IntProgress, HTML, VBox\n","    from IPython.display import display\n","\n","    is_iterator = False\n","    if size is None:\n","        try:\n","            size = len(sequence)\n","        except TypeError:\n","            is_iterator = True\n","    if size is not None:\n","        if every is None:\n","            if size <= 200:\n","                every = 1\n","            else:\n","                every = int(size / 200)     # every 0.5%\n","    else:\n","        assert every is not None, 'sequence is iterator, set every'\n","\n","    if is_iterator:\n","        progress = IntProgress(min=0, max=1, value=1)\n","        progress.bar_style = 'info'\n","    else:\n","        progress = IntProgress(min=0, max=size, value=0)\n","    label = HTML()\n","    box = VBox(children=[label, progress])\n","    display(box)\n","\n","    index = 0\n","    try:\n","        for index, record in enumerate(sequence, 1):\n","            if index == 1 or index % every == 0:\n","                if is_iterator:\n","                    label.value = '{name}: {index} / ?'.format(\n","                        name=name,\n","                        index=index\n","                    )\n","                else:\n","                    progress.value = index\n","                    label.value = u'{name}: {index} / {size}'.format(\n","                        name=name,\n","                        index=index,\n","                        size=size\n","                    )\n","            yield record\n","    except:\n","        progress.bar_style = 'danger'\n","        raise\n","    else:\n","        progress.bar_style = 'success'\n","        progress.value = index\n","        label.value = \"{name}: {index}\".format(\n","            name=name,\n","            index=str(index or '?')\n","        )\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_SlzLS_IOt4","cellView":"form","executionInfo":{"status":"ok","timestamp":1622547326893,"user_tz":-180,"elapsed":362,"user":{"displayName":"Артемий Двойное Дно","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG9pQ8FcJc9b3S76fMxNFSQB-LRvslG5G_q0XL=s64","userId":"12519032261696717131"}}},"source":["#@title Additional functions for point cloud generation\n","\n","\n","\n","def rotate(plane, angle):\n","    theta = np.radians(angle)\n","    # rot_x = np.array([[1, 0, 0], [0, np.cos(theta), -np.sin(theta)], [0, np.sin(theta), np.cos(theta)]])\n","    rot_y = np.array([[np.cos(theta), 0, np.sin(theta)], [0, 1, 0], [-np.sin(theta), 0, np.cos(theta)]])\n","    # rot_z = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [0, 0, 1]])\n","    return plane.dot(rot_y)\n","\n","\n","def img2points(img, d=0, a=0, thr=255):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    th = cv2.adaptiveThreshold(gray, thr, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 4)\n","    w, h = gray.shape\n","    depth = 1 - th / 255\n","    new_depth = depth + d\n","    pixel_x, pixel_y = np.meshgrid(np.linspace(0, w - 1, w),\n","                                   np.linspace(0, h - 1, h))\n","    camera_points = np.array([pixel_x, pixel_y, new_depth]).transpose(1, 2, 0).reshape(-1, 3)\n","    color_points = img.reshape(-1, 3)\n","    if a % 360 != 0:\n","        camera_points = rotate(camera_points, a)\n","\n","    valid_depth_ind = np.where(depth.flatten() > 0)[0]\n","    camera_points = camera_points[valid_depth_ind, :]\n","    color_points = color_points[valid_depth_ind, :]\n","    color_points = color_points.astype(int)\n","\n","    return camera_points, color_points\n","\n","\n","def write_pointcloud(filename, xyz_points, rgb_points=None):\n","    \"\"\" creates a .ply file of the generated point clouds \n","    \"\"\"\n","\n","    assert xyz_points.shape[1] == 3, 'Input XYZ points should be Nx3 float array'\n","    if rgb_points is None:\n","        rgb_points = np.ones(xyz_points.shape).astype(np.uint8) * 255\n","    assert xyz_points.shape == rgb_points.shape, 'Input RGB colors should be Nx3 float array and have same size as input XYZ points'\n","\n","    # Write header of .ply file\n","    with open(filename, 'wb') as fid:\n","        fid.write(bytes('ply\\n', 'utf-8'))\n","        fid.write(bytes('format binary_little_endian 1.0\\n', 'utf-8'))\n","        fid.write(bytes(f'element vertex {xyz_points.shape[0]}\\n', 'utf-8'))\n","        fid.write(bytes('property float x\\n', 'utf-8'))\n","        fid.write(bytes('property float y\\n', 'utf-8'))\n","        fid.write(bytes('property float z\\n', 'utf-8'))\n","        fid.write(bytes('property uchar red\\n', 'utf-8'))\n","        fid.write(bytes('property uchar green\\n', 'utf-8'))\n","        fid.write(bytes('property uchar blue\\n', 'utf-8'))\n","        fid.write(bytes('end_header\\n', 'utf-8'))\n","\n","        # Write 3D points to .ply file\n","        for i in range(xyz_points.shape[0]):\n","            fid.write(bytearray(struct.pack(\"fffBBB\", xyz_points[i, 0], xyz_points[i, 1], xyz_points[i, 2],\n","                                            rgb_points[i, 0], rgb_points[i, 1],\n","                                            rgb_points[i, 2])))\n","\n","\n","def sparse_image(img, level):\n","    new_image = np.zeros(img.shape, dtype=np.uint8)\n","    new_image.fill(255)\n","    new_image[::level,::level] = img[::level,::level]\n","    return new_image"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8pRlyqnYR67","cellView":"form"},"source":["#@title Mount Google Drive\n","#@markdown Mount Google Drive to load pretrained models and to save the results.\n","\n","#@markdown After running this cell you will get the link. Follow the link, grant access to your Drive and copy auth code.\n","\n","#@markdown Paste the code to the input below and press Enter\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6eDLUA27rv2","cellView":"form"},"source":["#@title Load StyleGAN2 model\n","#@markdown Provide the path to pretrained StyleGAN2 model (.pkl file)\n","network_pkl = \"/content/drive/MyDrive/stylegan/models/ucl-000032.pkl\" #@param {type: \"string\"}\n","dnnlib.tflib.init_tf()\n","\n","with dnnlib.util.open_url(network_pkl) as fp:\n","    _G, _D, Gs = pickle.load(fp)\n","noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jaNNNMDAIz1","cellView":"form"},"source":["#@title Image generation\n","\n","#@markdown Number of images\n","num_images = 10 #@param {type: \"integer\"}\n","#@markdown Number of interpolation steps\n","num_steps = 20 #@param {type: \"integer\"}\n","#@markdown Directory to save the results. This folder will be used to save images, video and point cloud\n","results_dir = \"/content/drive/MyDrive/workshops/ucl/pc4\" #@param {type: \"string\"}\n","\n","\n","if results_dir==\"\":\n","  raise Exception(\"Please specify results directory!\")\n","else:\n","  if results_dir[-1] != \"/\":\n","    results_dir += \"/\"\n","  results_images = f'{results_dir}images/'\n","  results_video = f'{results_dir}video/'\n","  results_cloud = f'{results_dir}cloud/'\n","  if not os.path.exists(results_dir):\n","    os.makedirs(results_dir)\n","    os.makedirs(results_images)\n","    os.makedirs(results_video)\n","    os.makedirs(results_cloud)\n","  else:\n","    raise Exception(\"This folder already exists!\")\n","\n","seeds = list(np.random.randint(4294967295, size=num_images))\n","seeds = seeds + [seeds[0]]\n","zs = generate_zs_from_seeds(seeds)\n","\n","imgs = generate_images(interpolate(zs, num_steps), 1)\n","\n","saveImgs(imgs, results_images)\n","with imageio.get_writer(results_video+'interpolate.mp4', mode='I') as writer:\n","    for image in log_progress(list(imgs), name = \"Creating animation\"):\n","        writer.append_data(np.array(image))\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Plsqgpp6LVg3","cellView":"form"},"source":["#@title Point Cloud Generation\n","\n","#@markdown Take every n-th point\n","skip = 10 #@param {type: \"integer\"}\n","#@markdown Distance between layers (if >1 distance will be bigger, if from 0 to 1 it will be scaled down)\n","distance = 1 #@param {type: \"number\"}\n","#@markdown Set point cloud file name\n","cloud_name = \"maps-test-point-cloud\" #@param {type: \"string\"}\n","\n","\n","if cloud_name==\"\":\n","  raise Exception(\"Please specify point cloud file name!\")\n","\n","total = num_images*num_steps\n","angle_shift = 360 / total\n","angle_current = -angle_shift\n","all_points = np.empty((0, 3))\n","all_colors = np.empty((0, 3))\n","\n","for i in range(total):\n","    if i % skip != 0:\n","        continue\n","    # print(f'{results_images}{i}.png')\n","    image = cv2.imread(f'{results_images}{i}.png', 1)\n","    image = sparse_image(image, skip)\n","    points, colors = img2points(image, d=i*distance, a=0)\n","    all_points = np.concatenate((all_points, points))\n","    all_colors = np.concatenate((all_colors, colors))\n","\n","\n","write_pointcloud(f'{results_cloud}{cloud_name}.ply', all_points, all_colors.astype(np.uint8))\n","print(f'Cloud saved to {results_cloud}{cloud_name}.ply')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MK3ybMHQ_Lep","cellView":"form"},"source":["#@title Images to Point Cloud\n","\n","#@markdown If you don't want to generate new imeges with GAN, but want to create point cloud from already existing images you can run this cell. Just be sure the first four cells are already executed.\n","\n","#@markdown Take every n-th point\n","skip = 10 #@param {type: \"integer\"}\n","#@markdown Distance between layers (if >1 distance will be bigger, if from 0 to 1 it will be scaled down)\n","distance = 1 #@param {type: \"number\"}\n","#@markdown Image directory\n","image_dir = \"/content/drive/MyDrive/workshops/ucl/CLIP\" #@param {type: \"string\"}\n","#@markdown Directory to save point cloud\n","results_cloud = \"/content/drive/MyDrive/workshops/ucl/pc4/cloud\" #@param {type: \"string\"}\n","#@markdown Set point cloud file name\n","cloud_name = \"maps-test-point-cloud-d3\" #@param {type: \"string\"}\n","\n","\n","if image_dir==\"\":\n","  raise Exception(\"Please specify image directory\")\n","if image_dir[-1] != \"/\":\n","    image_dir += \"/\"\n","if results_cloud==\"\":\n","  results_cloud= '/content/'\n","if results_cloud[-1] != \"/\":\n","    results_cloud += \"/\"\n","if not os.path.exists(results_cloud):\n","  os.makedirs(results_cloud)\n","if cloud_name==\"\":\n","  raise Exception(\"Please specify point cloud file name!\")\n","\n","img_files = sorted(glob.glob(f'{image_dir}*.png')+glob.glob(f'{image_dir}*.jpg'))\n","total = len(img_files)\n","angle_shift = 360 / total\n","angle_current = -angle_shift\n","all_points = np.empty((0, 3))\n","all_colors = np.empty((0, 3))\n","\n","\n","\n","for i, fname in enumerate(img_files):\n","    if i % skip != 0:\n","        continue\n","    image = cv2.imread(fname, 1)\n","    image = cv2.resize(image, (1024,1024), interpolation = cv2.INTER_LINEAR)\n","    image = sparse_image(image, skip)\n","    points, colors = img2points(image, d=i*distance, a=0)\n","    all_points = np.concatenate((all_points, points))\n","    all_colors = np.concatenate((all_colors, colors))\n","\n","\n","write_pointcloud(f'{results_cloud}{cloud_name}.ply', all_points, all_colors.astype(np.uint8))\n","print(f'Cloud saved to {results_cloud}{cloud_name}.ply')"],"execution_count":null,"outputs":[]}]}