{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"sg2-ada-pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qZkTQZc7cMWN"},"source":["# Custom Training StyleGan2-ADA\n","\n","In this notebook we will do transfer learning with StyleGAN2 and custom datasets.\n","\n","This means we will not train GAN on our images from scratch (as it takes about two weeks) but we will use the model already trained on the other images as a starting point. It will reduce training time to about 10 hours by skipping first stages where neural network learns low level features of images that are almost the same for any kind of images."]},{"cell_type":"code","metadata":{"id":"WOgc3AOiY6iU","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624857410633,"user_tz":-180,"elapsed":37932,"user":{"displayName":"Artem Konevskikh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzk0bqzeBuXtDrZ7vBWslL76vC9-a_i8tXACnzQQ=s64","userId":"00874259313111924918"}},"outputId":"f3a98d2e-91d9-4cae-cfe8-4f407492dae5"},"source":["#@title Mount Google Drive\n","#@markdown Mount Google Drive to load pretrained models and to save the results.\n","\n","#@markdown After running this cell you will get the link. Follow the link, grant access to your Drive and copy auth code.\n","\n","#@markdown Paste the code to the input below and press Enter\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G6nP8w7IZDpb","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624857442129,"user_tz":-180,"elapsed":30002,"user":{"displayName":"Artem Konevskikh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzk0bqzeBuXtDrZ7vBWslL76vC9-a_i8tXACnzQQ=s64","userId":"00874259313111924918"}},"outputId":"897f9496-6ca1-4938-e2f9-6a48357f0a94"},"source":["#@title Install\n","#@markdown StyleGAN2-ada will be installed to your Google Drive to speed up the training process\n","\n","#@markdown Run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary.\n","import os\n","import shlex\n","if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n","    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n","elif os.path.isdir(\"/content/drive/\"):\n","    #install script\n","    %cd \"/content/drive/MyDrive/\"\n","    !mkdir colab-sg2-ada-pytorch\n","    %cd colab-sg2-ada-pytorch\n","    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n","    %cd stylegan2-ada-pytorch\n","    !mkdir downloads\n","    !mkdir datasets\n","    !mkdir pretrained\n","    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n","else:\n","    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n","    %cd stylegan2-ada-pytorch\n","    !mkdir downloads\n","    !mkdir datasets\n","    !mkdir pretrained\n","    %cd pretrained\n","    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n","    %cd ../\n","\n","!pip install ninja opensimplex\n","\n","%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n","!git config --global user.name \"test\"\n","!git config --global user.email \"test@test.com\"\n","!git fetch origin\n","!git pull\n","!git stash\n","!git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n","Collecting ninja\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n","\u001b[K     |████████████████████████████████| 112kB 30.9MB/s \n","\u001b[?25hCollecting opensimplex\n","  Downloading https://files.pythonhosted.org/packages/9c/ad/9b758f9ff9dcd23fc574bb3aa1de844adb1179c9be9711e9f798614d4b2f/opensimplex-0.3-py3-none-any.whl\n","Installing collected packages: ninja, opensimplex\n","Successfully installed ninja-1.10.0.post2 opensimplex-0.3\n","/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n","Already up to date.\n","Saved working directory and index state WIP on main: af55ab4 flesh digressions now uses non-square\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-MgOcCseZqlA","cellView":"form"},"source":["#@title Data Preparation\n","#@markdown Input image directory\n","input_dir = '/content/drive/MyDrive/digitalfutures-workshop/datasets/nuclei1024' #@param {type: \"string\"}\n","#@markdown Path to the zip file where converted dataset will be stored\n","dataset_file = '/content/drive/MyDrive/digitalfutures-workshop/nuclei1024.zip' #@param {type: \"string\"}\n","\n","if not dataset_file.endswith('.zip'):\n","  dataset_file += '.zip'\n","input_dir = shlex.quote(input_dir)\n","dataset_file = shlex.quote(dataset_file)\n","!python dataset_tool.py --source {input_dir} --dest {dataset_file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E25JTmDbZX1z","cellView":"form"},"source":["#@title Train a custom model\n","\n","#@markdown Path to the dataset zip file\n","dataset = \"/content/drive/MyDrive/digitalfutures-workshop/nuclei1024.zip\" #@param {type: \"string\"}\n","\n","#@markdown For transfer learning set it to `ffhq256`, `ffhq512` or `ffhq1024`accordingly to your images resolution.<br />\n","#@markdown If you want to resume training process, provide the path to your latest .pkl file\n","resume_from = \"ffhq1024\" #@param {type: \"string\"}\n","\n","dataset = shlex.quote(dataset)\n","resume_from = shlex.quote(resume_from)\n","#don't edit this unless you know what you're doing :)\n","!python train.py --outdir ./results --snap=1 --cfg='11gb-gpu' --data={dataset} --aug=noaug --mirror=False --mirrory=False --metrics=None --resume={resume_from}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GwPrEVh5coPf"},"source":["### While it’s training...\n","**Once the above cell is running you should be training!**\n","\n","Don’t close this tab! Colab needs to be open and running in order to continue training. \n","\n","Every ~40min or so a new line should get added to your output, indicated its still training. Depending on you `snapshot_count` setting you should see the results folder (`/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada/results`) in your Google drive folder fill with both samples (`fakesXXXXXx.jpg`) and model weights (`network-snapshot-XXXXXX.pkl`). The samples are worth looking at while it trains but don’t get too worried about each individual sample.\n","\n","Once Colab shuts off, you can Reconnect the notebook and re-run every cell from top to bottom. Make sure you update the `resume_from` path to continue training from the latest model."]}]}